{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgg1FRTSW3dc"
   },
   "source": [
    "# ETL\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Diego Antonio GarcÃ­a Padilla\n",
    "\n",
    "**Date:** Oct 29, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7NJ0YPeYDGP"
   },
   "source": [
    "## Enviroment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "W4fFJZEDYJQe",
    "outputId": "0ffe40a3-bb98-4480-b921-b4df866ba5ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENVIRONMENT CHECK ===\n",
      "Python: 3.10.12\n",
      "JAVA_HOME: /usr/lib/jvm/java-8-openjdk-arm64/jre\n",
      "SPARK_HOME: /opt/spark\n",
      "Driver Memory: 8g\n",
      "Executor Memory: 4g\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#@title Setup & Environment Verification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"=== ENVIRONMENT CHECK ===\")\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"JAVA_HOME: {os.environ.get('JAVA_HOME')}\")\n",
    "print(f\"SPARK_HOME: {os.environ.get('SPARK_HOME')}\")\n",
    "print(f\"Driver Memory: {os.environ.get('SPARK_DRIVER_MEMORY')}\")\n",
    "print(f\"Executor Memory: {os.environ.get('SPARK_EXECUTOR_MEMORY')}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "5bgOQ8cpWmZX",
    "outputId": "53adea74-2017-427c-b585-78f7a992132b"
   },
   "outputs": [],
   "source": [
    "#@title Import Libraries\n",
    "\n",
    "# PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Financial data\n",
    "import yfinance as yf\n",
    "\n",
    "# Hugging Face\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Kaggle\n",
    "import kagglehub\n",
    "\n",
    "# Utilities\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import requests\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import subprocess\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ve3NLAzpd2bJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRE-FLIGHT CHECK ===\n",
      "Java: âœ… Available\n",
      "==================================================\n",
      "\n",
      "âœ… Spark 3.5.6 initialized successfully\n",
      "   Master: local[8]\n",
      "   App Name: SAPS_Sentiment_Analysis\n",
      "   Driver Memory: 8GB\n",
      "   Spark UI: http://localhost:4040\n"
     ]
    }
   ],
   "source": [
    "#@title Start Spark session\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "print(\"=== PRE-FLIGHT CHECK ===\")\n",
    "\n",
    "# Verify Java is available\n",
    "try:\n",
    "    java_version = subprocess.check_output(['java', '-version'], stderr=subprocess.STDOUT)\n",
    "    print(\"Java: âœ… Available\")\n",
    "except Exception as e:\n",
    "    print(f\"Java: âŒ Not available - {e}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create fresh Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SAPS_Sentiment_Analysis\") \\\n",
    "    .master(\"local[8]\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"100\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"1024m\") \\\n",
    "    .config(\"spark.local.dir\", \"/tmp/spark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(f\"\\nâœ… Spark {spark.version} initialized successfully\")\n",
    "print(f\"   Master: {spark.sparkContext.master}\")\n",
    "print(f\"   App Name: {spark.sparkContext.appName}\")\n",
    "print(f\"   Driver Memory: 8GB\")\n",
    "print(f\"   Spark UI: http://localhost:4040\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTdrxZmA4tbV"
   },
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /root/.cache/kagglehub/datasets/yelp-dataset/yelp-dataset/versions/4\n",
      "ðŸ“ Content of: /root/.cache/kagglehub/datasets/yelp-dataset/yelp-dataset/versions/4\n",
      "\n",
      "  ðŸ“„ Dataset_User_Agreement.pdf\n",
      "     Size: 0.08 MB\n",
      "  ðŸ“„ yelp_academic_dataset_business.json\n",
      "     Size: 113.36 MB\n",
      "  ðŸ“„ yelp_academic_dataset_checkin.json\n",
      "     Size: 273.67 MB\n",
      "  ðŸ“„ yelp_academic_dataset_review.json\n",
      "     Size: 5094.40 MB\n",
      "  ðŸ“„ yelp_academic_dataset_tip.json\n",
      "     Size: 172.24 MB\n",
      "  ðŸ“„ yelp_academic_dataset_user.json\n",
      "     Size: 3207.52 MB\n",
      "\n",
      "ðŸ’¾ Total size: 8.65 GB (8861.26 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9291705417"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Download Yelp reviews dataset\n",
    "\n",
    "yelp_path = kagglehub.dataset_download(\"yelp-dataset/yelp-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", yelp_path)\n",
    "\n",
    "def explore_dataset(path):\n",
    "    print(f\"ðŸ“ Content of: {path}\\n\")\n",
    "    total_size = 0\n",
    "    \n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            size = os.path.getsize(file_path)\n",
    "            total_size += size\n",
    "            size_mb = size / (1024 * 1024)\n",
    "            print(f\"  ðŸ“„ {file}\")\n",
    "            print(f\"     Size: {size_mb:.2f} MB\")\n",
    "    \n",
    "    total_gb = total_size / (1024 * 1024 * 1024)\n",
    "    print(f\"\\nðŸ’¾ Total size: {total_gb:.2f} GB ({total_size / (1024 * 1024):.2f} MB)\")\n",
    "    \n",
    "    return total_size\n",
    "\n",
    "explore_dataset(yelp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Explotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Already exists: ../data/raw/yelp_reviews_raw.parquet \n",
      "\n",
      "ðŸ”„ Loaded \n",
      "\n",
      "ðŸ“‹ Schema of Yelp Reviews:\n",
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- cool: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n",
      "\n",
      "ðŸ“Š Total reviews: 6,990,280\n",
      "\n",
      "ðŸ” Sample reviews:\n",
      "+----------------------+----+-------------------+-----+----------------------+-----+--------------------------------------------------+------+----------------------+\n",
      "|           business_id|cool|               date|funny|             review_id|stars|                                              text|useful|               user_id|\n",
      "+----------------------+----+-------------------+-----+----------------------+-----+--------------------------------------------------+------+----------------------+\n",
      "|znK6tMeegKf9YnGutYaG7Q|   0|2021-04-16 22:02:21|    0|MmmrqbdupYBJq9jnl3xjxw|  5.0|Great little spot with a relaxing atmosphere an...|     0|TjD2S66AWxlKsPSQBR1t-Q|\n",
      "|UxwpCVLgPWCeaRyetfCqCA|   0|2021-01-03 21:54:48|    0|1_uWX0bBJNnZjPEcpbaxHg|  5.0|James was super kind to come and sort our elect...|     0|Vtfxxq3nxdYHRiH6OAV59g|\n",
      "|eVI64EQymywsvMLmDLX04w|   0|2020-11-01 19:50:03|    0|WVAEE47MnM3Sv2cvM8869g|  5.0|By far the best italian in the area! We do both...|     0|ZDw_qN5Fy6PE0gdbVYvafQ|\n",
      "|SPcPJfPgWzhjUDqVFdsiOg|   0|2021-03-24 05:53:49|    0|D5b6iooZZcJ8nG-9PXDK4g|  5.0|I thought that this Burlington was pretty organ...|     0|UvMDlX2wV4Md9OwGW8G3gQ|\n",
      "|T5XzQ6YnVExvd0BOR26OMQ|   0|2016-06-13 21:25:10|    0|uDxnT7zWFnxEDxp5e3fEtQ|  5.0|Aside from the retro look, the quality of custo...|     0|ir9ixBZPzBwWe9IZ_7qsYA|\n",
      "+----------------------+----+-------------------+-----+----------------------+-----+--------------------------------------------------+------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "â­ Stars distribution:\n",
      "+-----+-------+\n",
      "|stars|  count|\n",
      "+-----+-------+\n",
      "|  1.0|1069561|\n",
      "|  2.0| 544240|\n",
      "|  3.0| 691934|\n",
      "|  4.0|1452918|\n",
      "|  5.0|3231627|\n",
      "+-----+-------+\n",
      "\n",
      "\n",
      "ðŸ“ Text statistics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:===============================================>        (34 + 6) / 40]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+----------+\n",
      "|       avg_length|min_length|max_length|\n",
      "+-----------------+----------+----------+\n",
      "|567.7644364746477|         1|      5000|\n",
      "+-----------------+----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#@title Load Yelp Reviews as Spark dataset\n",
    "\n",
    "# Parquet path\n",
    "parquet_path = \"../data/raw/yelp_reviews_raw.parquet\"\n",
    "\n",
    "if os.path.exists(parquet_path):\n",
    "    print(f\"âœ… Already exists: {parquet_path} \\n\")\n",
    "    df_reviews = spark.read.parquet(parquet_path)\n",
    "    print(f\"ðŸ”„ Loaded \\n\")\n",
    "else:\n",
    "    # Load the dataset\n",
    "    reviews_file = os.path.join(yelp_path, \"yelp_academic_dataset_review.json\")\n",
    "\n",
    "    # Read JSON file with Spark\n",
    "    df_reviews = spark.read.json(reviews_file)\n",
    "\n",
    "# Show schema to understand structure\n",
    "print(\"ðŸ“‹ Schema of Yelp Reviews:\")\n",
    "df_reviews.printSchema()\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nðŸ“Š Total reviews: {df_reviews.count():,}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nðŸ” Sample reviews:\")\n",
    "df_reviews.show(5, truncate=50)\n",
    "\n",
    "# Check stars distribution\n",
    "print(\"\\nâ­ Stars distribution:\")\n",
    "df_reviews.groupBy('stars').count().orderBy('stars').show()\n",
    "\n",
    "# Check text lengths\n",
    "\n",
    "print(\"\\nðŸ“ Text statistics:\")\n",
    "df_reviews.select(\n",
    "    F.avg(F.length(F.col('text'))).alias('avg_length'),\n",
    "    F.min(F.length(F.col('text'))).alias('min_length'),\n",
    "    F.max(F.length(F.col('text'))).alias('max_length')\n",
    ").show()\n",
    "\n",
    "if not os.path.exists(parquet_path):\n",
    "    df_reviews.write.parquet(parquet_path, mode=\"overwrite\")\n",
    "    print(f\"\\nðŸ’¾ Parquet saved: {parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Sample dataset created: 1,397,232 reviews\n",
      "\n",
      "ðŸŽ¯ Sentiment distribution:\n",
      "   positive: 936,506 (67.0%)\n",
      "   neutral: 138,512 (9.9%)\n",
      "   negative: 322,214 (23.1%)\n",
      "\n",
      "ðŸ“Œ Sample reviews:\n",
      "\n",
      "NEGATIVE (1.0 stars):\n",
      "   What has the world come when you have to argue with staff in order to get corn salsa on your burrito bowl at a Mexican restaurant? Was repeatedly told...\n",
      "\n",
      "NEUTRAL (3.0 stars):\n",
      "   My 91-yr-old mom and I stayed here for a weekend in June while visiting family and attending a concert downtown. My overall reaction to our stay was t...\n",
      "\n",
      "POSITIVE (5.0 stars):\n",
      "   Love this local hangout. Not many bells or whistles but it has a great whisky selection and a solid crew of bar tenders manning all 24 hours of day an...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:============================================>           (32 + 8) / 40]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¾ Parquet saved: ../data/filtered/yelp_reviews_sentiment.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#@title Sample dataset\n",
    "\n",
    "# Parquet path\n",
    "parquet_path = \"../data/filtered/yelp_reviews_sentiment.parquet\"\n",
    "\n",
    "if os.path.exists(parquet_path):\n",
    "    print(f\"âœ… Already exists: {parquet_path}\")\n",
    "    df_sentiment = spark.read.parquet(parquet_path)\n",
    "    print(f\"ðŸ”„ Loaded\")\n",
    "else:\n",
    "    #  Sample directly from the original dataframe with stars\n",
    "    # 10% sample = ~700K reviews (still >1GB when processed with text)\n",
    "    df_sample = df_reviews.sample(fraction=0.20, seed=42)\n",
    "\n",
    "    # Create sentiment column\n",
    "    df_sentiment = df_sample.select(\n",
    "        F.col('review_id'),\n",
    "        F.col('text'),\n",
    "        F.col('stars'),\n",
    "        F.col('useful'),\n",
    "        F.col('date')\n",
    "    ).withColumn('sentiment',\n",
    "        F.when(F.col('stars').isin([1.0, 2.0]), 'negative')\n",
    "        .when(F.col('stars') == 3.0, 'neutral')\n",
    "        .when(F.col('stars').isin([4.0, 5.0]), 'positive')\n",
    "    )\n",
    "\n",
    "# Single count operation\n",
    "total_reviews = df_sentiment.count()\n",
    "print(f\"\\nâœ… Sample dataset created: {total_reviews:,} reviews\")\n",
    "\n",
    "# Get distribution (single pass)\n",
    "print(\"\\nðŸŽ¯ Sentiment distribution:\")\n",
    "sentiment_counts = df_sentiment.groupBy('sentiment').count().collect()\n",
    "for row in sentiment_counts:\n",
    "    percentage = (row['count'] / total_reviews) * 100\n",
    "    print(f\"   {row['sentiment']}: {row['count']:,} ({percentage:.1f}%)\")\n",
    "\n",
    "# Show one sample per sentiment (lightweight)\n",
    "print(\"\\nðŸ“Œ Sample reviews:\")\n",
    "for sent in ['negative', 'neutral', 'positive']:\n",
    "    sample = df_sentiment.filter(F.col('sentiment') == sent).select('text', 'stars').first()\n",
    "    if sample:\n",
    "        print(f\"\\n{sent.upper()} ({sample['stars']} stars):\")\n",
    "        print(f\"   {sample['text'][:150]}...\")\n",
    "\n",
    "df_sentiment.write.parquet(parquet_path, mode=\"overwrite\")\n",
    "print(f\"\\nðŸ’¾ Parquet saved: {parquet_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:======================================================> (39 + 1) / 40]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|                text|sentiment|\n",
      "+--------------------+---------+\n",
      "|I've been here fo...| positive|\n",
      "|Absolute nightmar...| negative|\n",
      "|Not sure who dump...| negative|\n",
      "|**READ BEFORE BUY...| negative|\n",
      "|I happened on to ...| positive|\n",
      "|Had an amazing ex...| positive|\n",
      "|I was looking for...| negative|\n",
      "|Do NOT go here an...| negative|\n",
      "|My first time try...| negative|\n",
      "|All I can say is ...| negative|\n",
      "+--------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#@title Select relevant features\n",
    "\n",
    "df_filtered = df_sentiment.select(\"text\", \"sentiment\") \\\n",
    "                .dropDuplicates()\n",
    "\n",
    "df_filtered.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Text statistics by sentiment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+------------------+------+\n",
      "|sentiment|       avg_length|         avg_words| count|\n",
      "+---------+-----------------+------------------+------+\n",
      "| positive|501.6060316978746| 92.66772888873696|936088|\n",
      "|  neutral|668.9137329664854|125.21409331513537|138477|\n",
      "| negative|717.3848549682797| 135.7392441147336|322033|\n",
      "+---------+-----------------+------------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:==================================================>     (36 + 4) / 40]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+---------+\n",
      "|                                                                            text|                                                                      text_clean|sentiment|\n",
      "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+---------+\n",
      "|I've been here for happy hour! I love the cocktail drinks/names. Everything i...|ive been here for happy hour i love the cocktail drinksnames everything is ph...| positive|\n",
      "|Absolute nightmare. It started to rain so they shut everything down except fo...|absolute nightmare it started to rain so they shut everything down except for...| negative|\n",
      "|Not sure who dumps out hot coffee 45 minutes prior to closing their doors. Al...|not sure who dumps out hot coffee 45 minutes prior to closing their doors als...| negative|\n",
      "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#@title Clean text\n",
    "\n",
    "# Add text length\n",
    "df_clean = df_filtered.withColumn('text_length', F.length(F.col('text')))\n",
    "\n",
    "# Add word count\n",
    "df_clean = df_clean.withColumn('word_count', \n",
    "    F.size(F.split(F.col('text'), ' ')))\n",
    "\n",
    "# Statistics by sentiment\n",
    "print(\"\\nðŸ“Š Text statistics by sentiment:\")\n",
    "df_clean.groupBy('sentiment').agg(\n",
    "    F.avg('text_length').alias('avg_length'),\n",
    "    F.avg('word_count').alias('avg_words'),\n",
    "    F.count('*').alias('count')\n",
    ").show()\n",
    "\n",
    "# Clean text: lowercase, remove special characters\n",
    "df_clean = df_clean.withColumn('text_clean',\n",
    "    F.lower(F.regexp_replace(F.col('text'), '[^a-zA-Z0-9\\\\s]', ''))\n",
    ")\n",
    "\n",
    "df_clean.select('text', 'text_clean', 'sentiment').show(3, truncate=80)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "pYXI8VZp5_If"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
